{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9wuNpeK5+0uylJztjDjA4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush-ds-phy/Pytorch_yt/blob/main/iris_nn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "A_DAs3zTuVgl"
      },
      "outputs": [],
      "source": [
        "#Importing\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as f\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self, in_feat=4, h1=7, h2=7, out_feat=3):  #Constructor â€” sets up the object when created\n",
        "    super().__init__()\n",
        "    self.fc1=nn.Linear(in_feat,h1)\n",
        "    self.fc2=nn.Linear(h1,h2)\n",
        "    self.fcf=nn.Linear(h2,out_feat)\n",
        "  def forward(self, x):  # method\n",
        "    x=f.relu(self.fc1(x))\n",
        "    x=f.relu(self.fc2(x))\n",
        "    x=self.fcf(x)\n",
        "\n",
        "    return x\n",
        "# Function for user based output\n",
        "def out(new_iris):\n",
        "    new_tensor= torch.tensor([new_iris],dtype= torch.float32)\n",
        "    k=model(new_tensor)\n",
        "    x=k.argmax().item()\n",
        "    if x==0:\n",
        "        x='Setosa'\n",
        "    if x==1:\n",
        "        x= 'Versicolour'\n",
        "    if x==2:\n",
        "        x= 'Virginica'\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "4iX4YurlvUfm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the seed\n",
        "torch.manual_seed(32)\n",
        "model= Model() #Created an instance of Model Class\n",
        "url='https://gist.githubusercontent.com/curran/a08a1080b88344b0c8a7/raw/0e7a9b0a5d22642a06d3d5b9bcbad9890c8ee534/iris.csv'\n",
        "my_df= pd.read_csv(url)\n",
        "my_df['species'] =my_df['species'].replace(['setosa','versicolor','virginica'],[0,1,2]) # Replaced to do computation\n",
        "print (my_df) #Checking Out the data set after replacement"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPCVuUQHxDxM",
        "outputId": "619628ac-03e1-46a5-d791-960ab3cd7c11"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     sepal_length  sepal_width  petal_length  petal_width  species\n",
            "0             5.1          3.5           1.4          0.2        0\n",
            "1             4.9          3.0           1.4          0.2        0\n",
            "2             4.7          3.2           1.3          0.2        0\n",
            "3             4.6          3.1           1.5          0.2        0\n",
            "4             5.0          3.6           1.4          0.2        0\n",
            "..            ...          ...           ...          ...      ...\n",
            "145           6.7          3.0           5.2          2.3        2\n",
            "146           6.3          2.5           5.0          1.9        2\n",
            "147           6.5          3.0           5.2          2.0        2\n",
            "148           6.2          3.4           5.4          2.3        2\n",
            "149           5.9          3.0           5.1          1.8        2\n",
            "\n",
            "[150 rows x 5 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-2540188094>:6: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  my_df['species'] =my_df['species'].replace(['setosa','versicolor','virginica'],[0,1,2]) # Replaced to do computation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X= my_df.drop('species',axis=1)\n",
        "y= my_df['species']\n",
        "X= X.values\n",
        "y= y.values"
      ],
      "metadata": {
        "id": "KRvaO-P_2pPr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.2,random_state=32)\n",
        "X_train= torch.FloatTensor(X_train)\n",
        "X_test= torch.FloatTensor(X_test)\n",
        "y_train= torch.LongTensor(y_train)\n",
        "y_test= torch.LongTensor(y_test)"
      ],
      "metadata": {
        "id": "ikY8xJmc_fPt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion= nn.CrossEntropyLoss() #error\n",
        "optimizer= torch.optim.Adam(model.parameters(),lr=0.01) #lr = learning rate,"
      ],
      "metadata": {
        "collapsed": true,
        "id": "5BnQ4mFgAV7N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tranning\n",
        "epoch= 100\n",
        "losses= []\n",
        "for i in range (epoch):\n",
        "  y_pred= model.forward(X_train)\n",
        "  loss= criterion(y_pred,y_train)\n",
        "  losses.append(loss.item())\n",
        "  if i%10==0:\n",
        "     print(f'epoch: {i} loss: {loss}')\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XzJ_jj7HCMh",
        "outputId": "170158da-325b-48a9-936b-4ec6e1a6187b",
        "collapsed": true
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 loss: 0.05551958084106445\n",
            "epoch: 10 loss: 0.05486106872558594\n",
            "epoch: 20 loss: 0.054266996681690216\n",
            "epoch: 30 loss: 0.05372338369488716\n",
            "epoch: 40 loss: 0.05322008579969406\n",
            "epoch: 50 loss: 0.05274975672364235\n",
            "epoch: 60 loss: 0.05230734124779701\n",
            "epoch: 70 loss: 0.05188894271850586\n",
            "epoch: 80 loss: 0.05149179697036743\n",
            "epoch: 90 loss: 0.05111369118094444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  y_eval = model.forward(X_test)\n",
        "  loss= criterion(y_eval,y_test)\n",
        ""
      ],
      "metadata": {
        "id": "KBpa_b_Ev5ZF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "with torch.no_grad():\n",
        "  for i,data in enumerate(X_test):\n",
        "      y_val= model.forward(data)\n",
        "\n",
        "      if y_test[i]==0:\n",
        "        x= 'Setosa'\n",
        "      if y_test[i]==1:\n",
        "        x= 'Versicolour'\n",
        "      if y_test[i]==2:\n",
        "        x= 'Virginica'\n",
        "\n",
        "      print(f'{i+1}.)  {str(y_val)} \\t    {y_test[i]} \\t {y_val.argmax().item()} \\t folower maybe= {x}')\n",
        "\n",
        "      # seeing how many of them we got right\n",
        "      if y_val.argmax().item() == y_test[i]:\n",
        "        correct += 1\n",
        "  print(f'No of correct answers :{correct}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "md3st8YKwgu1",
        "outputId": "a150a89a-9e80-41c2-c50d-b41423a6e8c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.)  tensor([-4.4158,  6.9628,  1.4972]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "2.)  tensor([ 3.9060, -6.7512, -7.9046]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "3.)  tensor([ 2.9271, -4.7271, -7.0264]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "4.)  tensor([-4.8127,  7.2139,  1.8158]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "5.)  tensor([-7.8690,  3.6252,  7.0407]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "6.)  tensor([-9.0668,  4.6367,  7.8745]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "7.)  tensor([ 2.5091, -3.8587, -6.6147]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "8.)  tensor([ 3.2376, -5.3738, -7.3465]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "9.)  tensor([-4.2471,  7.4300,  1.0737]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "10.)  tensor([ 3.3866, -5.6924, -7.5754]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "11.)  tensor([-5.0253,  7.7593,  1.7801]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "12.)  tensor([-9.0436,  1.8774,  9.2340]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "13.)  tensor([-2.6003,  6.8360, -0.8675]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "14.)  tensor([-2.6825,  6.9544, -1.2571]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "15.)  tensor([-8.0196,  3.4250,  7.3100]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "16.)  tensor([-8.7936,  1.2442,  9.2718]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "17.)  tensor([-4.8162,  6.2128,  2.3222]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "18.)  tensor([-7.1508,  4.2059,  5.9448]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "19.)  tensor([-2.8140,  7.2478, -0.9449]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "20.)  tensor([ 3.7067, -6.3825, -8.1151]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "21.)  tensor([ 2.8877, -4.6562, -7.0853]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "22.)  tensor([-10.0207,   2.6463,   9.9423]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "23.)  tensor([-6.4881,  4.6073,  5.0010]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "24.)  tensor([ 3.2198, -5.3299, -7.2672]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "25.)  tensor([ 3.3871, -5.6501, -7.1861]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "26.)  tensor([-2.9519,  7.5281, -0.8659]) \t    1 \t 1 \t folower maybe= Versicolour\n",
            "27.)  tensor([ 3.7822, -6.5356, -8.1552]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "28.)  tensor([-10.2328,   0.8636,  11.0750]) \t    2 \t 2 \t folower maybe= Virginica\n",
            "29.)  tensor([ 3.5000, -5.9384, -7.7805]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "30.)  tensor([ 3.3966, -5.7163, -7.6131]) \t    0 \t 0 \t folower maybe= Setosa\n",
            "No of correct answers :30\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For User Input\n",
        "User_i= []\n",
        "val = float(input(\"Enter Sepal Length :\"))\n",
        "User_i.append(val)\n",
        "val = float(input(\"Enter Sepal Width :\"))\n",
        "User_i.append(val)\n",
        "val = float(input(\"Enter Petal Length :\"))\n",
        "User_i.append(val)\n",
        "val = float(input(\"Enter Petal Width :\"))\n",
        "User_i.append(val)\n",
        "\n",
        "print(f'The flower is most likely: {out(User_i)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlKkWykj3Sdy",
        "outputId": "1becf9ad-d7b9-4818-9b05-263e0756ef48"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter Sepal Length :4\n",
            "Enter Sepal Width :3\n",
            "Enter Petal Length :5\n",
            "Enter Petal Width :6\n",
            "The flower is most likely: Virginica\n"
          ]
        }
      ]
    }
  ]
}